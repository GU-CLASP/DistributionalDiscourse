{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from util import gen_model_preds_df\n",
    "\n",
    "with open('SWDA_dialogue-acts.json') as f:\n",
    "    swda_tags = json.load(f)\n",
    "with open('AMI-DA_dialogue-acts.json') as f:\n",
    "    ami_tags = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-domain / cross-domain pre-training \n",
    "First we want to see how in-domain pre-training compares to cross domain pre-training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_metrics(frames, conditions):\n",
    "    metric_funcs = [\n",
    "        lambda x,y: metrics.precision_score(x,y,average='macro'), \n",
    "        lambda x,y: metrics.recall_score(x,y,average='macro'), \n",
    "        lambda x,y: metrics.f1_score(x,y,average='macro'),\n",
    "        lambda x,y: metrics.precision_score(x,y,average='micro')]\n",
    "    metric_names = [\n",
    "        'macro precision',\n",
    "        'macro recall',\n",
    "        'macro f1',\n",
    "        'micro accuracy']\n",
    "    table = [[\n",
    "        metric(df['da_tag'], df[cond])\n",
    "            for df in frames]\n",
    "            for cond in conditions for metric in metric_funcs]\n",
    "    multiindex = [[c for c in conditions for m in metric_names],\n",
    "        [m for c in conditions for m in metric_names]]\n",
    "    return pd.DataFrame(table, columns=['SWBD', 'AMI'], index=multiindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xnobwi/.virtualenvs/transformers/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>SWBD</th>\n",
       "      <th>AMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">in-domain</th>\n",
       "      <th>macro precision</th>\n",
       "      <td>0.562046</td>\n",
       "      <td>0.523854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro recall</th>\n",
       "      <td>0.417171</td>\n",
       "      <td>0.453892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro f1</th>\n",
       "      <td>0.454760</td>\n",
       "      <td>0.465609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro accuracy</th>\n",
       "      <td>0.770237</td>\n",
       "      <td>0.686575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">AMI+SWBD</th>\n",
       "      <th>macro precision</th>\n",
       "      <td>0.589477</td>\n",
       "      <td>0.543774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro recall</th>\n",
       "      <td>0.441669</td>\n",
       "      <td>0.469115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro f1</th>\n",
       "      <td>0.477812</td>\n",
       "      <td>0.487214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro accuracy</th>\n",
       "      <td>0.773529</td>\n",
       "      <td>0.685840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               SWBD       AMI\n",
       "in-domain macro precision  0.562046  0.523854\n",
       "          macro recall     0.417171  0.453892\n",
       "          macro f1         0.454760  0.465609\n",
       "          micro accuracy   0.770237  0.686575\n",
       "AMI+SWBD  macro precision  0.589477  0.543774\n",
       "          macro recall     0.441669  0.469115\n",
       "          macro f1         0.477812  0.487214\n",
       "          micro accuracy   0.773529  0.685840"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions = ['in-domain', 'AMI+SWBD']\n",
    "\n",
    "pre_corpora = ['SWBD-pre', 'AMI+SWBD-pre']\n",
    "model_dirs = [f'../../models/SWDA-L_bert_{corpus}_2019-12-03/' for corpus in pre_corpora]\n",
    "dfs = gen_model_preds_df('SWDA', conditions, model_dirs)\n",
    "\n",
    "pre_corpora = ['AMI-pre', 'AMI+SWBD-pre']\n",
    "model_dirs = [f'../../models/AMI-DA-L_bert_{corpus}_2019-12-03/' for corpus in pre_corpora]\n",
    "dfa = gen_model_preds_df('AMI-DA', conditions, model_dirs)\n",
    "dfa = dfa[dfa['da_tag'].notnull()]\n",
    "\n",
    "report_metrics([dfs,dfa], conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-training on the combined corpus offers a modest improvement in macro-averaged F1 over simple in-domain pre-training, though there is little effect on micro-averaged performance.\n",
    "This indicates that pre-training on the lareger, more diverse dataset is helpful for classification of lower-frequency tags. \n",
    "A larger pre-training corpus may lead to more significant gains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>SWBD</th>\n",
       "      <th>AMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">in-domain</th>\n",
       "      <th>macro precision</th>\n",
       "      <td>0.562046</td>\n",
       "      <td>0.523854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro recall</th>\n",
       "      <td>0.417171</td>\n",
       "      <td>0.453892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro f1</th>\n",
       "      <td>0.454760</td>\n",
       "      <td>0.465609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro accuracy</th>\n",
       "      <td>0.770237</td>\n",
       "      <td>0.686575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">standard</th>\n",
       "      <th>macro precision</th>\n",
       "      <td>0.561119</td>\n",
       "      <td>0.587054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro recall</th>\n",
       "      <td>0.430470</td>\n",
       "      <td>0.483137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro f1</th>\n",
       "      <td>0.459891</td>\n",
       "      <td>0.500326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro accuracy</th>\n",
       "      <td>0.769267</td>\n",
       "      <td>0.669527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">in-domain_frozen</th>\n",
       "      <th>macro precision</th>\n",
       "      <td>0.077394</td>\n",
       "      <td>0.270771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro recall</th>\n",
       "      <td>0.077295</td>\n",
       "      <td>0.174683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro f1</th>\n",
       "      <td>0.064646</td>\n",
       "      <td>0.144316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro accuracy</th>\n",
       "      <td>0.522999</td>\n",
       "      <td>0.480653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">standard_frozen</th>\n",
       "      <th>macro precision</th>\n",
       "      <td>0.120535</td>\n",
       "      <td>0.150745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro recall</th>\n",
       "      <td>0.083235</td>\n",
       "      <td>0.173323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro f1</th>\n",
       "      <td>0.077471</td>\n",
       "      <td>0.144419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro accuracy</th>\n",
       "      <td>0.556122</td>\n",
       "      <td>0.466002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      SWBD       AMI\n",
       "in-domain        macro precision  0.562046  0.523854\n",
       "                 macro recall     0.417171  0.453892\n",
       "                 macro f1         0.454760  0.465609\n",
       "                 micro accuracy   0.770237  0.686575\n",
       "standard         macro precision  0.561119  0.587054\n",
       "                 macro recall     0.430470  0.483137\n",
       "                 macro f1         0.459891  0.500326\n",
       "                 micro accuracy   0.769267  0.669527\n",
       "in-domain_frozen macro precision  0.077394  0.270771\n",
       "                 macro recall     0.077295  0.174683\n",
       "                 macro f1         0.064646  0.144316\n",
       "                 micro accuracy   0.522999  0.480653\n",
       "standard_frozen  macro precision  0.120535  0.150745\n",
       "                 macro recall     0.083235  0.173323\n",
       "                 macro f1         0.077471  0.144419\n",
       "                 micro accuracy   0.556122  0.466002"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions = ['in-domain', 'standard', 'in-domain_frozen', 'standard_frozen']\n",
    "\n",
    "model_dirs = [\n",
    "    '../../models/SWDA-L_bert_SWBD-pre_2019-12-03/',\n",
    "    '../../models/SWDA-L_bert_2019-11-20',\n",
    "    '../../models/SWDA-L_bert_SWBD-pre_frozen_2019-12-03',\n",
    "    '../../models/SWDA-L_bert_frozen_2019-11-20']\n",
    "dfs = gen_model_preds_df('SWDA', conditions, model_dirs)\n",
    "\n",
    "model_dirs = [\n",
    "    '../../models/AMI-DA-L_bert_AMI-pre_2019-12-03/',\n",
    "    '../../models/AMI-DA-L_bert_2019-11-20',\n",
    "    '../../models/AMI-DA-L_bert_AMI-pre_frozen_2019-12-03',\n",
    "    '../../models/AMI-DA-L_bert_frozen_2019-11-20']\n",
    "dfa = gen_model_preds_df('AMI-DA', conditions, model_dirs)\n",
    "dfa = dfa[dfa['da_tag'].notnull()]\n",
    "\n",
    "report_metrics([dfs,dfa], conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The effect of additional pre-training is mixed. For AMI it appears that in-domain pre-training offers a modest performance boost, but there is no discernable effect in the case of Switchboard. Indeed, when BERT is frozen during fine-tuning, the model that received no additional pre-traininig performs better by more than 3 percentage points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>SWBD</th>\n",
       "      <th>AMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">addl-pre</th>\n",
       "      <th>macro precision</th>\n",
       "      <td>0.562046</td>\n",
       "      <td>0.523854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro recall</th>\n",
       "      <td>0.417171</td>\n",
       "      <td>0.453892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro f1</th>\n",
       "      <td>0.454760</td>\n",
       "      <td>0.465609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro accuracy</th>\n",
       "      <td>0.770237</td>\n",
       "      <td>0.686575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">standard</th>\n",
       "      <th>macro precision</th>\n",
       "      <td>0.561119</td>\n",
       "      <td>0.587054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro recall</th>\n",
       "      <td>0.430470</td>\n",
       "      <td>0.483137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro f1</th>\n",
       "      <td>0.459891</td>\n",
       "      <td>0.500326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro accuracy</th>\n",
       "      <td>0.769267</td>\n",
       "      <td>0.669527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">addl-pre-NL</th>\n",
       "      <th>macro precision</th>\n",
       "      <td>0.560160</td>\n",
       "      <td>0.551050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro recall</th>\n",
       "      <td>0.433200</td>\n",
       "      <td>0.456565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro f1</th>\n",
       "      <td>0.459774</td>\n",
       "      <td>0.477635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro accuracy</th>\n",
       "      <td>0.770868</td>\n",
       "      <td>0.680196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">standard-NL</th>\n",
       "      <th>macro precision</th>\n",
       "      <td>0.455734</td>\n",
       "      <td>0.592475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro recall</th>\n",
       "      <td>0.367783</td>\n",
       "      <td>0.464749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro f1</th>\n",
       "      <td>0.381006</td>\n",
       "      <td>0.489605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro accuracy</th>\n",
       "      <td>0.770665</td>\n",
       "      <td>0.669025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 SWBD       AMI\n",
       "addl-pre    macro precision  0.562046  0.523854\n",
       "            macro recall     0.417171  0.453892\n",
       "            macro f1         0.454760  0.465609\n",
       "            micro accuracy   0.770237  0.686575\n",
       "standard    macro precision  0.561119  0.587054\n",
       "            macro recall     0.430470  0.483137\n",
       "            macro f1         0.459891  0.500326\n",
       "            micro accuracy   0.769267  0.669527\n",
       "addl-pre-NL macro precision  0.560160  0.551050\n",
       "            macro recall     0.433200  0.456565\n",
       "            macro f1         0.459774  0.477635\n",
       "            micro accuracy   0.770868  0.680196\n",
       "standard-NL macro precision  0.455734  0.592475\n",
       "            macro recall     0.367783  0.464749\n",
       "            macro f1         0.381006  0.489605\n",
       "            micro accuracy   0.770665  0.669025"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions = ['addl-pre', 'standard', 'addl-pre-NL', 'standard-NL']\n",
    "\n",
    "model_dirs = [\n",
    "    '../../models/SWDA-L_bert_SWBD-pre_2019-12-03/',\n",
    "    '../../models/SWDA-L_bert_2019-11-20',\n",
    "    '../../models/SWDA-NL_bert_SWBD-pre_2019-12-03/',\n",
    "    '../../models/SWDA-NL_bert_2019-11-20']\n",
    "dfs = gen_model_preds_df('SWDA', conditions, model_dirs)\n",
    "\n",
    "model_dirs = [\n",
    "    '../../models/AMI-DA-L_bert_AMI-pre_2019-12-03/',\n",
    "    '../../models/AMI-DA-L_bert_2019-11-20',\n",
    "    '../../models/AMI-DA-NL_bert_AMI-pre_2019-12-03/',\n",
    "    '../../models/AMI-DA-NL_bert_2019-11-20']\n",
    "dfa = gen_model_preds_df('AMI-DA', conditions, model_dirs)\n",
    "dfa = dfa[dfa['da_tag'].notnull()]\n",
    "\n",
    "\n",
    "report_metrics([dfs,dfa], conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
