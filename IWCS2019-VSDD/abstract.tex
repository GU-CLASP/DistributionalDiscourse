\documentclass[11pt,a4paper,headings=standardclasses]{article}

\usepackage[margin=1in]{geometry}
\usepackage{url}
\usepackage{hyperref}
\usepackage{natbib}
\usepackage{tikz}
\usepackage[bf]{caption}

\title{Neural dialogue act recognition with transformer pre-training} % or something like that...

\author{
  First Author \\
  Affiliation / Address \\
  %Affiliation / Address line 1 \\
  %Affiliation / Address line 2 \\
%Affiliation / Address line 3 \\
  {\texttt email@domain} \\\and
  Second Author \\
  Affiliation / Address \\
  %Affiliation / Address line 1 \\
  %Affiliation / Address line 2 \\
  %Affiliation / Address line 3 \\
  {\texttt email@domain} \\
}
 

\date{}

\begin{document}
\maketitle

Dialogue acts represent the meaning of an utterance by the speech act it carries out \citep{austinHowThingsWords2009}.
Dialogue act recognition (DAR) is the task of automatically labeling utterances with tags from a dialogue act schema such as DAMSL \citep{coreCodingDialogsDAMSL1997}.

Dialogue acts depend on their conversational context.
For example, a speaker may use \textit{okay} to agree with their interlocutor, answer a yes-no question in the affirmative, 
or simply acknowledge the previous utterance, depending on what has transpired in the conversation so far.
Naturally, many DAR strategies attempt to model discourse context in addition to considering the content of the utterance in question.
\cite{stolckeDialogueActModeling2000}, for example, use a Hidden Markov Model to tag dialogue acts.
The hidden state of neural sequence models can also be used to represent discourse context 
\citep[e.g.][]{kalchbrennerRecurrentConvolutionalNeural2013,tranPreservingDistributionalInformation2017}.

%Another approach learns representations of utterances by attempting to predict their conversational context directly,
%in much the same way that word2vec attempts to predict context words \citep{pragstVectorRepresentationUtterances2018}.
%The authors find that these utterance representations cluster in a way that corresponds closely to dialogue act tags
%that were unavailable to the model at training time.
%conversely, this result raises the possibility that a hidden state learned in service of DAR may be used to represent 
%a more general notion of discourse context.

It is now standard practice in NLP to initialize semantic word representations
with pre-trained distributional word vectors such as word2vec \citep{mikolov2013distributed}.
More recently, multi-layer neural language models pre-trained on massive amounts unlabeled data
have been used to provide contextually sensitive word vectors and sentence-level distributional representations.
One such model, BERT, uses an attention-based transformer architecture to achieve state of the art results
on a variety of NLP tasks \citep{devlinBERTPretrainingDeep2018}.

However, given that BERT is pre-trained on book and encyclopedia data, 
there is no guarantee it will improve performance on dialogue-specific tasks.
Adding to that uncertainty, we note that word2vec is not consistently beneficial for DAR \citep{cerisaraEffectsUsingWord2vec2017}.
To assess BERT's potential for dialogue applications, we propose a series of DAR experiments 
with various utterance encoders, including BERT.
Utterance representations are then fed to a simple RNN to predict sequences of dialogue acts (figure~\ref{fig:architecture}).
In particular, we are interested in whether BERT can be fine-tuned to adequately represent
dialogue-specific features such as discourse markers, disfluencies, and non-verbal vocalizations such as laughter. 

%%% RELATED WORK NOTES %%%
%
% cerisaraEffectsUsingWord2vec2017
%     - Use LSTM with and without word2vec initialization to encode discourse utterances and predict dialogue act tags.
%     - No notion of discourse context.
%     - Word2vec does not improve dialogue act recoginition, possibly becasue it does not capture lexical-semantic information relevant to dialogue.
% khanpourDialogueActClassification}
%     - Uses RNN and stacked LSTM with word2vec embeddings to encode utterances.
%     - No notion of discourse context.
% pragstVectorRepresentationUtterances2018} --
%     - Uses a skip thought approach to learn utterance representations by predicting context utterances.
% kalchbrennerRecurrentConvolutionalNeural2013} --
%     - Encode utterances (sentences) convolution-based composition of the sequence of words (HCNN). 
%     - Use an RNN with agent-specific weights to produce utterance label predictions.
%     - Also talk about the hidden layer of the RNN as representing discourse context. 
% tranPreservingDistributionalInformation2017} --
%     - Propogates a distribution over dialogue acts instead of greedily choosing a lable at each step, a kind of discourse context.
% stolckeDialogueActModeling2000
%     - classic HMM DAR 
% chen2018dialogue
%     - SOTA dialogue act recoginition, uses 
% sordoniNeuralNetworkApproach2015} 
%     - generate utterances taking into account previous countext

%\paragraph{Model.}
%The proposed model has two components: an utterance encoder, and a sequence model that predicts the dialogue act tag.
%For the sequence model, we use a simple RNN.
%Conceptually the hidden state of this RNN represents the discourse context which, 
%together with the encoded utterance, is used to predict the discourse act tag.

\input{architecture-diagram.tex}

\paragraph{Experiments.}
Our aim is to test the effectiveness of different utterance encoding strategies. We investigate the following strategies:
\begin{enumerate}
  \item Averaging of word2vec/BERT word embedding
  \item Encoding utterances with CNN (with/without word2vec/BERT initalization, with/without `freezing' the embeddings)
  \item BERT encoded sentences (with/without additional unsupervised pretraining on the full Switchboard corpus)
  \end{enumerate}

  Pre-trained models benefit from learning on large amounts of online data, however it might be the case that for DAR, additional information only present in natural dialogue data will be useful. In SWDA disfluencies are annotated and for the datasets where no annotation for disfluencies is available, they can be predicted from recognized speech \citep{hough2017joint,shalyminov2018multi}. We evaluate the impact of disfluencies and non-verbal signals, such as laughter, on the performance of our models and suggest the ways to include information about disfluencies into pre-trained neural models. 

  % PoS tags?

\bibliography{abstract}{}
\bibliographystyle{acl_natbib}

\end{document}

