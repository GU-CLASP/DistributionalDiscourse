
@inproceedings{coreCodingDialogsDAMSL1997,
  address = {{Boston, MA}},
  title = {Coding {{Dialogs}} with the {{DAMSL Annotation Scheme}}},
  abstract = {This paper describes the DAMSL annotation scheme for communicative acts in dialog. The scheme has three layers: Forward Communicative Functions, Backward Communicative Functions, and Utterance Features. Each layer allows multiple communicative functions of an utterance to be labeled. The Forward Communicative Functions consist of a taxonomy in a similar style as the actions of traditional speech act theory. The Backward Communicative Functions indicate how the current utterance relates to the previous dialog, such as accepting a proposal, con rming understanding, or answering a question. The Utterance Features include information about an utterance's form and content, such as whether an utterance concerns the communication process itself or deals with the subject at hand. The kappa inter-annotator reliability scores for the rst test of DAMSL with human annotators show promise, but are on average 0.15 lower than the accepted kappa scores for such annotations. However, the slight revisions to DAMSL discussed here should increase accuracy on the next set of tests and produce a reliable, exible, and comprehensive utterance annotation scheme.},
  language = {en},
  booktitle = {Working {{Notes}} of the {{AAAI Fall Symposium}} on {{Communicative Action}} in {{Humans}} and {{Machines}}},
  author = {Core, Mark G and Allen, James F},
  year = {1997},
  pages = {28-35},
  file = {/Users/xnobwi/.zotero/storage/BKUWT57X/Core and Allen - Coding Dialogs with the DAMSL Annotation Scheme.pdf}
}

@inproceedings{pragstVectorRepresentationUtterances2018,
  title = {On the {{Vector Representation}} of {{Utterances}} in {{Dialogue Context}}},
  booktitle = {Proceedings of the {{Eleventh International Conference}} on {{Language Resources}} and {{Evaluation}} ({{LREC}}-2018)},
  publisher = {{European Language Resource Association}},
  author = {Pragst, Louisa and Rach, Niklas and Minker, Wolfgang and Ultes, Stefan},
  year = {2018},
  keywords = {suggestion},
  file = {/Users/xnobwi/.zotero/storage/3DEGXJPE/Pragst et al. - 2018 - On the Vector Representation of Utterances in Dial.pdf}
}

@article{devlinBERTPretrainingDeep2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1810.04805},
  primaryClass = {cs},
  title = {{{BERT}}: {{Pre}}-Training of {{Deep Bidirectional Transformers}} for {{Language Understanding}}},
  shorttitle = {{{BERT}}},
  abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT representations can be fine-tuned with just one additional output layer to create state-of-theart models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications.},
  language = {en},
  journal = {arXiv:1810.04805 [cs]},
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  month = oct,
  year = {2018},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/xnobwi/.zotero/storage/CD98FF2E/Devlin et al. - 2018 - BERT Pre-training of Deep Bidirectional Transform.pdf}
}

@article{cerisaraEffectsUsingWord2vec2017,
  title = {On the Effects of Using Word2vec Representations in Neural Networks for Dialogue Act Recognition},
  volume = {47},
  issn = {08852308},
  language = {en},
  journal = {Computer Speech \& Language},
  doi = {10.1016/j.csl.2017.07.009},
  author = {Cerisara, Christophe and Kr{\'a}l, Pavel and Lenc, Ladislav},
  year = {2017},
  pages = {175-193},
  file = {/Users/xnobwi/.zotero/storage/4WXBE8SF/1-s2.0-S0885230816300456-main.pdf}
}

@book{austinHowThingsWords2009,
  address = {{Cambridge, Mass}},
  edition = {2. ed., [repr.]},
  title = {How to Do Things with Words: The {{William James}} Lectures Delivered at {{Harvard University}} in 1955},
  isbn = {978-0-674-41152-4},
  shorttitle = {How to Do Things with Words},
  language = {eng},
  publisher = {{Harvard Univ. Press}},
  author = {Austin, John L. and Urmson, James O.},
  year = {2009},
  file = {/Users/xnobwi/.zotero/storage/2MCXA76R/Austin - HOW TO DO THINGS WITH WORDS.pdf},
  note = {OCLC: 935786421}
}

@inproceedings{kalchbrennerRecurrentConvolutionalNeural2013,
  title = {Recurrent {{Convolutional Neural Networks}} for {{Discourse Compositionality}}},
  abstract = {The compositionality of meaning extends beyond the single sentence. Just as words combine to form the meaning of sentences, so do sentences combine to form the meaning of paragraphs, dialogues and general discourse. We introduce both a sentence model and a discourse model corresponding to the two levels of compositionality. The sentence model adopts convolution as the central operation for composing semantic vectors and is based on a novel hierarchical convolutional neural network. The discourse model extends the sentence model and is based on a recurrent neural network that is conditioned in a novel way both on the current sentence and on the current speaker. The discourse model is able to capture both the sequentiality of sentences and the interaction between different speakers. Without feature engineering or pretraining and with simple greedy decoding, the discourse model coupled to the sentence model obtains state of the art performance on a dialogue act classification experiment.},
  language = {en},
  booktitle = {Proceedings of the {{Workshop}} on {{Continuous Vector Space Models}} and Their {{Compositionality}}},
  author = {Kalchbrenner, Nal and Blunsom, Phil},
  year = {2013},
  pages = {119-126},
  file = {/Users/xnobwi/.zotero/storage/SRUYIRW5/Kalchbrenner and Blunsom - Recurrent Convolutional Neural Networks for Discou.pdf}
}

@article{stolckeDialogueActModeling2000,
  title = {Dialogue {{Act Modeling}} for {{Automatic Tagging}} and {{Recognition}} of {{Conversational Speech}}},
  volume = {26},
  issn = {0891-2017, 1530-9312},
  language = {en},
  number = {3},
  journal = {Computational Linguistics},
  doi = {10.1162/089120100561737},
  author = {Stolcke, Andreas and Ries, Klaus and Coccaro, Noah and Shriberg, Elizabeth and Bates, Rebecca and Jurafsky, Daniel and Taylor, Paul and Martin, Rachel and {Ess-Dykema}, Carol Van and Meteer, Marie},
  month = sep,
  year = {2000},
  pages = {339-373},
  file = {/Users/xnobwi/.zotero/storage/E2RM82HV/Stolcke et al. - 2000 - Dialogue Act Modeling for Automatic Tagging and Re.pdf},
  ids = {stolckeDialogueActModeling2000a}
}

@inproceedings{sordoniNeuralNetworkApproach2015,
  address = {{Denver, Colorado}},
  title = {A {{Neural Network Approach}} to {{Context}}-{{Sensitive Generation}} of {{Conversational Responses}}},
  abstract = {We present a novel response generation system that can be trained end to end on large quantities of unstructured Twitter conversations. A neural network architecture is used to address sparsity issues that arise when integrating contextual information into classic statistical models, allowing the system to take into account previous dialog utterances. Our dynamic-context generative models show consistent gains over both context-sensitive and non-context-sensitive Machine Translation and Information Retrieval baselines.},
  language = {en},
  booktitle = {Proceedings of the 2015 {{Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Human Language Technologies}}},
  publisher = {{Association for Computational Linguistics}},
  doi = {10.3115/v1/N15-1020},
  author = {Sordoni, Alessandro and Galley, Michel and Auli, Michael and Brockett, Chris and Ji, Yangfeng and Mitchell, Margaret and Nie, Jian-Yun and Gao, Jianfeng and Dolan, Bill},
  year = {2015},
  pages = {196-205},
  file = {/Users/xnobwi/.zotero/storage/6QR84V9B/Sordoni et al. - 2015 - A Neural Network Approach to Context-Sensitive Gen.pdf}
}

@inproceedings{khanpourDialogueActClassification2016,
  address = {{Osaka, Japan}},
  title = {Dialogue {{Act Classification}} in {{Domain}}-{{Independent Conversations Using}} a {{Deep Recurrent Neural Network}}},
  abstract = {In this study, we applied a deep LSTM structure to classify dialogue acts (DAs) in open-domain conversations. We found that the word embeddings parameters, dropout regularization, decay rate and number of layers are the parameters that have the largest effect on the final system accuracy. Using the findings of these experiments, we trained a deep LSTM network that outperforms the state-of-the-art on the Switchboard corpus by 3.11\%, and MRDA by 2.2\%.},
  language = {en},
  booktitle = {Proceedings of {{COLING}} 2016, the 26th {{International Conference}} on {{Computational Linguistics}}: {{Technical Papers}}},
  author = {Khanpour, Hamed and Guntakandla, Nishitha and Nielsen, Rodney},
  month = dec,
  year = {2016},
  pages = {2012-2021},
  file = {/Users/xnobwi/.zotero/storage/79IVLLM8/Khanpour et al. - Dialogue Act Classification in Domain-Independent .pdf}
}

@inproceedings{tranPreservingDistributionalInformation2017,
  address = {{Copenhagen, Denmark}},
  title = {Preserving {{Distributional Information}} in {{Dialogue Act Classification}}},
  abstract = {This paper introduces a novel training/decoding strategy for sequence labeling. Instead of greedily choosing a label at each time step, and using it for the next prediction, we retain the probability distribution over the current label, and pass this distribution to the next prediction. This approach allows us to avoid the effect of label bias and error propagation in sequence learning/decoding. Our experiments on dialogue act classification demonstrate the effectiveness of this approach. Even though our underlying neural network model is relatively simple, it outperforms more complex neural models, achieving state-of-the-art results on the MapTask and Switchboard corpora.},
  language = {en},
  booktitle = {Proceedings of the 2017 {{Conference}} on {{Empirical Methods}} in {{Natural}}           {{Language Processing}}},
  publisher = {{Association for Computational Linguistics}},
  doi = {10.18653/v1/D17-1229},
  author = {Tran, Quan Hung and Zukerman, Ingrid and Haffari, Gholamreza},
  year = {2017},
  pages = {2151-2156},
  file = {/Users/xnobwi/.zotero/storage/LDF2M2KJ/Tran et al. - 2017 - Preserving Distributional Information in Dialogue .pdf}
}

@article{mikolovDistributedRepresentationsWords2013,
  title = {Distributed {{Representations}} of {{Words}} and {{Phrases}} and Their {{Compositionality}}},
  abstract = {The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling.},
  language = {en},
  journal = {NIPS Proceedings},
  author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
  year = {2013},
  pages = {9},
  file = {/Users/xnobwi/.zotero/storage/FPRM9TKD/Mikolov et al. - Distributed Representations of Words and Phrases a.pdf}
}

@article{chenDialogueActRecognition2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1711.05568},
  primaryClass = {cs},
  title = {Dialogue {{Act Recognition}} via {{CRF}}-{{Attentive Structured Network}}},
  abstract = {Dialogue Act Recognition (DAR) is a challenging problem in dialogue interpretation, which aims to attach semantic labels to utterances and characterize the speaker's intention. Currently, many existing approaches formulate the DAR problem ranging from multi-classification to structured prediction, which suffer from handcrafted feature extensions and attentive contextual structural dependencies. In this paper, we consider the problem of DAR from the viewpoint of extending richer Conditional Random Field (CRF) structural dependencies without abandoning end-to-end training. We incorporate hierarchical semantic inference with memory mechanism on the utterance modeling. We then extend structured attention network to the linear-chain conditional random field layer which takes into account both contextual utterances and corresponding dialogue acts. The extensive experiments on two major benchmark datasets Switchboard Dialogue Act (SWDA) and Meeting Recorder Dialogue Act (MRDA) datasets show that our method achieves better performance than other state-of-the-art solutions to the problem. It is a remarkable fact that our method is nearly close to the human annotator's performance on SWDA within 2\% gap.},
  journal = {arXiv:1711.05568 [cs]},
  author = {Chen, Zheqian and Yang, Rongqin and Zhao, Zhou and Cai, Deng and He, Xiaofei},
  month = nov,
  year = {2017},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/xnobwi/.zotero/storage/Q4MKJ7GY/Chen et al. - 2017 - Dialogue Act Recognition via CRF-Attentive Structu.pdf}
}

@inproceedings{ortegaNeuralbasedContextRepresentation2017,
  address = {{Saarbr{\"u}cken, Germany}},
  title = {Neural-Based {{Context Representation Learning}} for {{Dialog Act Classification}}},
  abstract = {We explore context representation learning methods in neural-based models for dialog act classification. We propose and compare extensively different methods which combine recurrent neural network architectures and attention mechanisms (AMs) at different context levels. Our experimental results on two benchmark datasets show consistent improvements compared to the models without contextual information and reveal that the most suitable AM in the architecture depends on the nature of the dataset.},
  language = {en},
  booktitle = {Proceedings of the 18th {{Annual SIGdial Meeting}} on {{Discourse}} and {{Dialogue}}},
  publisher = {{Association for Computational Linguistics}},
  doi = {10.18653/v1/W17-5530},
  author = {Ortega, Daniel and Vu, Ngoc Thang},
  year = {2017},
  pages = {247-252},
  file = {/Users/xnobwi/.zotero/storage/7YWQZXWG/Ortega and Vu - 2017 - Neural-based Context Representation Learning for D.pdf;/Users/xnobwi/.zotero/storage/F87RLCJT/Ortega and Vu - 2017 - Neural-based Context Representation Learning for D.pdf}
}

@article{shenNeuralAttentionModels2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1604.00077},
  primaryClass = {cs},
  title = {Neural {{Attention Models}} for {{Sequence Classification}}: {{Analysis}} and {{Application}} to {{Key Term Extraction}} and {{Dialogue Act Detection}}},
  shorttitle = {Neural {{Attention Models}} for {{Sequence Classification}}},
  abstract = {Recurrent neural network architectures combining with attention mechanism, or neural attention model, have shown promising performance recently for the tasks including speech recognition, image caption generation, visual question answering and machine translation. In this paper, neural attention model is applied on two sequence classification tasks, dialogue act detection and key term extraction. In the sequence labeling tasks, the model input is a sequence, and the output is the label of the input sequence. The major difficulty of sequence labeling is that when the input sequence is long, it can include many noisy or irrelevant part. If the information in the whole sequence is treated equally, the noisy or irrelevant part may degrade the classification performance. The attention mechanism is helpful for sequence classification task because it is capable of highlighting important part among the entire sequence for the classification task. The experimental results show that with the attention mechanism, discernible improvements were achieved in the sequence labeling task considered here. The roles of the attention mechanism in the tasks are further analyzed and visualized in this paper.},
  journal = {arXiv:1604.00077 [cs]},
  author = {Shen, Sheng-syun and Lee, Hung-yi},
  month = mar,
  year = {2016},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/xnobwi/.zotero/storage/DGLRKFZP/Shen and Lee - 2016 - Neural Attention Models for Sequence Classificatio.pdf}
}

@inproceedings{tranHierarchicalNeuralModel2017,
  address = {{Valencia, Spain}},
  title = {A {{Hierarchical Neural Model}} for {{Learning Sequences}} of {{Dialogue Acts}}},
  abstract = {We propose a novel hierarchical Recurrent Neural Network (RNN) for learning sequences of Dialogue Acts (DAs). The input in this task is a sequence of utterances (i.e., conversational contributions) comprising a sequence of tokens, and the output is a sequence of DA labels (one label per utterance). Our model leverages the hierarchical nature of dialogue data by using two nested RNNs that capture long-range dependencies at the dialogue level and the utterance level. This model is combined with an attention mechanism that focuses on salient tokens in utterances. Our experimental results show that our model outperforms strong baselines on two popular datasets, Switchboard and MapTask; and our detailed empirical analysis highlights the impact of each aspect of our model.},
  language = {en},
  booktitle = {Proceedings of the 15th {{Conference}} of the {{European Chapter}} of the           {{Association}} for {{Computational Linguistics}}: {{Volume}} 1, {{Long Papers}}},
  publisher = {{Association for Computational Linguistics}},
  doi = {10.18653/v1/E17-1041},
  author = {Tran, Quan Hung and Zukerman, Ingrid and Haffari, Gholamreza},
  year = {2017},
  pages = {428-437},
  file = {/Users/xnobwi/.zotero/storage/FDT4SJK7/Tran et al. - 2017 - A Hierarchical Neural Model for Learning Sequences.pdf}
}

@article{petersTuneNotTune2019,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1903.05987},
  primaryClass = {cs},
  title = {To {{Tune}} or {{Not}} to {{Tune}}? {{Adapting Pretrained Representations}} to {{Diverse Tasks}}},
  shorttitle = {To {{Tune}} or {{Not}} to {{Tune}}?},
  abstract = {While most previous work has focused on different pretraining objectives and architectures for transfer learning, we ask how to best adapt the pretrained model to a given target task. We focus on the two most common forms of adaptation, feature extraction (where the pretrained weights are frozen), and directly fine-tuning the pretrained model. Our empirical results across diverse NLP tasks with two state-of-the-art models show that the relative performance of fine-tuning vs. feature extraction depends on the similarity of the pretraining and target tasks. We explore possible explanations for this finding and provide a set of adaptation guidelines for the NLP practitioner.},
  journal = {arXiv:1903.05987 [cs]},
  author = {Peters, Matthew and Ruder, Sebastian and Smith, Noah A.},
  month = mar,
  year = {2019},
  keywords = {Computer Science - Machine Learning,Computer Science - Computation and Language,to-read},
  file = {/Users/xnobwi/.zotero/storage/GL2C9FD2/Peters et al. - 2019 - To Tune or Not to Tune Adapting Pretrained Repres.pdf}
}

@incollection{searleTaxonomyIllocutionaryActs1979,
  address = {{Cambridge}},
  title = {A {{Taxonomy}} of {{Illocutionary Acts}}},
  isbn = {978-0-511-60921-3},
  language = {en},
  booktitle = {Expression and {{Meaning}}: {{Studies}} in the {{Theory}} of {{Speech Acts}}},
  publisher = {{Cambridge University Press}},
  doi = {10.1017/CBO9780511609213},
  author = {Searle, John R.},
  year = {1979},
  file = {/Users/xnobwi/.zotero/storage/ZBMMP8UC/Searle - 1979 - Expression and Meaning Studies in the Theory of S.pdf}
}

@article{jurafskyLexicalProsodicSyntactic,
  title = {Lexical, {{Prosodic}}, and {{Syntactic Cues}} for {{Dialog Acts}}},
  language = {en},
  author = {Jurafsky, Daniel and Shriberg, Elizabeth and Fox, Barbara and Curl, Traci},
  pages = {7},
  file = {/Users/xnobwi/.zotero/storage/P2CXTYCL/Jurafsky et al. - Lexical, Prosodic, and Syntactic Cues for Dialog A.pdf}
}

@article{baoPLATOPretrainedDialogue2019,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1910.07931},
  primaryClass = {cs},
  title = {{{PLATO}}: {{Pre}}-Trained {{Dialogue Generation Model}} with {{Discrete Latent Variable}}},
  shorttitle = {{{PLATO}}},
  abstract = {Pre-training models have been proved effective for a wide range of natural language processing tasks. Inspired by this, we propose a novel dialogue generation pre-training framework to support various kinds of conversations, including chit-chat, knowledge grounded dialogues, and conversational question answering. In this framework, we adopt flexible attention mechanisms to fully leverage the bi-directional context and the uni-directional characteristic of language generation. We also introduce discrete latent variables to tackle with the natural born one-to-many mapping problem in response generation. Two reciprocal tasks of response generation and latent act recognition are designed and carried out simultaneously within a shared network. Comprehensive experiments on three publicly available datasets verify the effectiveness and superiority of the proposed framework.},
  journal = {arXiv:1910.07931 [cs]},
  author = {Bao, Siqi and He, Huang and Wang, Fan and Wu, Hua},
  month = oct,
  year = {2019},
  keywords = {Computer Science - Computation and Language,to-read},
  file = {/Users/xnobwi/.zotero/storage/XCZNIHJ7/Bao et al. - 2019 - PLATO Pre-trained Dialogue Generation Model with .pdf}
}

@article{mehriStructuredFusionNetworks2019,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1907.10016},
  primaryClass = {cs},
  title = {Structured {{Fusion Networks}} for {{Dialog}}},
  abstract = {Neural dialog models have exhibited strong performance, however their end-to-end nature lacks a representation of the explicit structure of dialog. This results in a loss of generalizability, controllability and a datahungry nature. Conversely, more traditional dialog systems do have strong models of explicit structure. This paper introduces several approaches for explicitly incorporating structure into neural models of dialog. Structured Fusion Networks first learn neural dialog modules corresponding to the structured components of traditional dialog systems and then incorporate these modules in a higher-level generative model. Structured Fusion Networks obtain strong results on the MultiWOZ dataset, both with and without reinforcement learning. Structured Fusion Networks are shown to have several valuable properties, including better domain generalizability, improved performance in reduced data scenarios and robustness to divergence during reinforcement learning.},
  language = {en},
  journal = {arXiv:1907.10016 [cs]},
  author = {Mehri, Shikib and Srinivasan, Tejas and Eskenazi, Maxine},
  month = jul,
  year = {2019},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Computation and Language,to-read},
  file = {/Users/xnobwi/.zotero/storage/RNT7SBKH/Mehri et al. - 2019 - Structured Fusion Networks for Dialog.pdf}
}

@article{hancherClassificationCooperativeIllocutionary1979,
  title = {The {{Classification}} of {{Cooperative Illocutionary Acts}}},
  volume = {8},
  issn = {0047-4045},
  abstract = {The different taxonomies of illocutionary acts proposed by Austin, Searle, Vendler, Ohmann, and Fraser are compared in summary form, with Searle's taxonomy taken as a reference standard. All five of these taxonomies slight two kinds of illocutionary act: (1) illocutionary acts that combine commissive with directive illocutionary force (e.g., offering, inviting, challenging), and (2) illocutionary acts that require two participants (e.g., giving, selling, contracting). These and related speech acts are discussed in some detail, and Searle's classification is amended to take them into account.},
  number = {1},
  journal = {Language in Society},
  author = {Hancher, Michael},
  year = {1979},
  pages = {1-14},
  file = {/Users/xnobwi/.zotero/storage/89BSGSSF/Hancher - 1979 - The classification of cooperative illocutionary ac.pdf}
}

@inproceedings{chenSemanticallyConditionedDialog2019a,
  address = {{Florence, Italy}},
  title = {Semantically {{Conditioned Dialog Response Generation}} via {{Hierarchical Disentangled Self}}-{{Attention}}},
  abstract = {Semantically controlled neural response generation on limited-domain has achieved great performance. However, moving towards multi-domain large-scale scenarios are shown to be difficult because the possible combinations of semantic inputs grow exponentially with the number of domains. To alleviate such scalability issue, we exploit the structure of dialog acts to build a multi-layer hierarchical graph, where each act is represented as a root-to-leaf route on the graph. Then, we incorporate such graph structure prior as an inductive bias to build a hierarchical disentangled self-attention network, where we disentangle attention heads to model designated nodes on the dialog act graph. By activating different (disentangled) heads at each layer, combinatorially many dialog act semantics can be modeled to control the neural response generation. On the large-scale Multi-Domain-WOZ dataset, our model can yield a significant improvement over the baselines on various automatic and human evaluation metrics.},
  booktitle = {Proceedings of the 57th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  publisher = {{Association for Computational Linguistics}},
  doi = {10.18653/v1/P19-1360},
  author = {Chen, Wenhu and Chen, Jianshu and Qin, Pengda and Yan, Xifeng and Wang, William Yang},
  month = jul,
  year = {2019},
  pages = {3696--3709},
  file = {/Users/xnobwi/.zotero/storage/62JRNAFP/Chen et al. - 2019 - Semantically Conditioned Dialog Response Generatio.pdf}
}

@inproceedings{mehriPretrainingMethodsDialog2019,
  address = {{Florence, Italy}},
  title = {Pretraining {{Methods}} for {{Dialog Context Representation Learning}}},
  abstract = {This paper examines various unsupervised pretraining objectives for learning dialog context representations. Two novel methods of pretraining dialog context encoders are proposed, and a total of four methods are examined. Each pretraining objective is fine-tuned and evaluated on a set of downstream dialog tasks using the MultiWoz dataset and strong performance improvement is observed. Further evaluation shows that our pretraining objectives result in not only better performance, but also better convergence, models that are less data hungry and have better domain generalizability.},
  language = {en},
  booktitle = {Proceedings of the 57th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  publisher = {{Association for Computational Linguistics}},
  doi = {10.18653/v1/P19-1373},
  author = {Mehri, Shikib and Razumovskaia, Evgeniia and Zhao, Tiancheng and Eskenazi, Maxine},
  year = {2019},
  pages = {3836-3845},
  file = {/Users/xnobwi/.zotero/storage/YGZWYMI5/Mehri et al. - 2019 - Pretraining Methods for Dialog Context Representat.pdf}
}

@inproceedings{vigComparisonTransferLearningApproaches2019,
  address = {{Honolulu, Hawaii}},
  title = {Comparison of {{Transfer}}-{{Learning Approaches}} for {{Response Selection}} in {{Multi}}-{{Turn Conversations}}},
  abstract = {This paper compares three transfer-learning approaches to response selection in dialogs, as part of the Dialog System Technology Challenge 7 (DSTC7) Track 1. In the first approach, Multi-Turn ESIM+ELMo (MT-EE), we incorporate pre-trained contextual embeddings into a sentence-pair model that was originally designed for natural language inference. In the second approach, we fine-tune the Generative Pre-trained Transformer (OpenAI GPT) model. In the third approach, we fine-tune the Bidirectional Encoder Representations from Transformers (BERT) model. Our results show that BERT performed best, followed by the GPT model and then the MTEE model. We also discuss the relative advantages and disadvantages of each approach. The submitted result for Track 1 (MT-EE) placed second and fifth overall for the Advising and Ubuntu datasets respectively.},
  language = {en},
  booktitle = {Proceedings of the {{Workshop}} on {{Dialog System Technology Challenges}}},
  author = {Vig, Jesse and Ramea, Kalai},
  month = jan,
  year = {2019},
  pages = {7},
  file = {/Users/xnobwi/.zotero/storage/93DAJXW4/Vig and Ramea - Comparison of Transfer-Learning Approaches for Res.pdf}
}

@article{kimConvolutionalNeuralNetworks2014,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1408.5882},
  primaryClass = {cs},
  title = {Convolutional {{Neural Networks}} for {{Sentence Classification}}},
  abstract = {We report on a series of experiments with convolutional neural networks (CNN) trained on top of pre-trained word vectors for sentence-level classification tasks. We show that a simple CNN with little hyperparameter tuning and static vectors achieves excellent results on multiple benchmarks. Learning task-specific vectors through fine-tuning offers further gains in performance. We additionally propose a simple modification to the architecture to allow for the use of both task-specific and static vectors. The CNN models discussed herein improve upon the state of the art on 4 out of 7 tasks, which include sentiment analysis and question classification.},
  language = {en},
  journal = {arXiv:1408.5882 [cs]},
  author = {Kim, Yoon},
  month = sep,
  year = {2014},
  keywords = {Computer Science - Neural and Evolutionary Computing,Computer Science - Computation and Language},
  file = {/Users/xnobwi/.zotero/storage/YITJI45Q/Kim - 2014 - Convolutional Neural Networks for Sentence Classif.pdf}
}

@article{sunHowFineTuneBERT2019,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1905.05583},
  primaryClass = {cs},
  title = {How to {{Fine}}-{{Tune BERT}} for {{Text Classification}}?},
  abstract = {Language model pre-training has proven to be useful in learning universal language representations. As a state-of-the-art language model pre-training model, BERT (Bidirectional Encoder Representations from Transformers) has achieved amazing results in many language understanding tasks. In this paper, we conduct exhaustive experiments to investigate different fine-tuning methods of BERT on text classification task and provide a general solution for BERT fine-tuning. Finally, the proposed solution obtains new state-of-the-art results on eight widely-studied text classification datasets.},
  language = {en},
  journal = {arXiv:1905.05583 [cs]},
  author = {Sun, Chi and Qiu, Xipeng and Xu, Yige and Huang, Xuanjing},
  month = aug,
  year = {2019},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/xnobwi/.zotero/storage/42ZLQ7BG/Sun et al. - 2019 - How to Fine-Tune BERT for Text Classification.pdf}
}

@misc{jurafskySwitchboardSWBDDAMSLShallowDiscourseFunction1997a,
  title = {Switchboard {{SWBD}}-{{DAMSL Shallow}}-{{Discourse}}-{{Function Annotation Coders Manual}}},
  author = {Jurafsky, Daniel and Shriberg, Liz and Biasca, Debra},
  year = {1997}
}

@inproceedings{penningtonGloveGlobalVectors2014,
  address = {{Doha, Qatar}},
  title = {Glove: {{Global Vectors}} for {{Word Representation}}},
  shorttitle = {Glove},
  booktitle = {Proceedings of the 2014 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
  publisher = {{Association for Computational Linguistics}},
  doi = {10.3115/v1/D14-1162},
  author = {Pennington, Jeffrey and Socher, Richard and Manning, Christopher},
  month = oct,
  year = {2014},
  pages = {1532--1543},
  file = {/Users/xnobwi/.zotero/storage/L5YPWP53/Pennington et al. - 2014 - Glove Global Vectors for Word Representation.pdf}
}

@article{wolfHuggingFaceTransformersStateoftheart2019,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1910.03771},
  primaryClass = {cs},
  title = {{{HuggingFace}}'s {{Transformers}}: {{State}}-of-the-Art {{Natural Language Processing}}},
  shorttitle = {{{HuggingFace}}'s {{Transformers}}},
  abstract = {Recent advances in modern Natural Language Processing (NLP) research have been dominated by the combination of Transfer Learning methods with large-scale language models, in particular based on the Transformer architecture. With them came a paradigm shift in NLP with the starting point for training a model on a downstream task moving from a blank specific model to a general-purpose pretrained architecture. Still, creating these general-purpose models remains an expensive and time-consuming process restricting the use of these methods to a small sub-set of the wider NLP community. In this paper, we present HuggingFace's Transformers library, a library for state-of-the-art NLP, making these developments available to the community by gathering state-of-the-art general-purpose pretrained models under a unified API together with an ecosystem of libraries, examples, tutorials and scripts targeting many downstream NLP tasks. HuggingFace's Transformers library features carefully crafted model implementations and high-performance pretrained weights for two main deep learning frameworks, PyTorch and TensorFlow, while supporting all the necessary tools to analyze, evaluate and use these models in downstream tasks such as text/token classification, questions answering and language generation among others. The library has gained significant organic traction and adoption among both the researcher and practitioner communities. We are committed at HuggingFace to pursue the efforts to develop this toolkit with the ambition of creating the standard library for building NLP systems.},
  journal = {arXiv:1910.03771 [cs]},
  author = {Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'e}mi and Funtowicz, Morgan and Brew, Jamie},
  month = oct,
  year = {2019},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/xnobwi/.zotero/storage/FH8M8CJC/Wolf et al. - 2019 - HuggingFace's Transformers State-of-the-art Natur.pdf}
}

@inproceedings{botheContextbasedApproachDialogue2018,
  address = {{Miyazaki, Japan}},
  title = {A {{Context}}-Based {{Approach}} for {{Dialogue Act Recognition}} Using {{Simple Recurrent Neural Networks}}},
  booktitle = {Proceedings of the {{Eleventh International Conference}} on {{Language Resources}} and {{Evaluation}} ({{LREC}} 2018)},
  publisher = {{European Language Resources Association (ELRA)}},
  author = {Bothe, Chandrakant and Weber, Cornelius and Magg, Sven and Wermter, Stefan},
  month = may,
  year = {2018},
  file = {/Users/xnobwi/.zotero/storage/LDUY9W8Y/Bothe et al. - 2018 - A Context-based Approach for Dialogue Act Recognit.pdf}
}

@misc{GuidelinesDialogueAct2005,
  title = {Guidelines for {{Dialogue Act}} and {{Addressee Annotation Version}} 1.0},
  month = oct,
  year = {2005},
  file = {/Users/xnobwi/.zotero/storage/7QSQ6H7G/dialogue_acts_manual_1.0.pdf}
}


