
@inproceedings{coreCodingDialogsDAMSL1997,
  title = {Coding {{Dialogs}} with the {{DAMSL Annotation Scheme}}},
  abstract = {This paper describes the DAMSL annotation scheme for communicative acts in dialog. The scheme has three layers: Forward Communicative Functions, Backward Communicative Functions, and Utterance Features. Each layer allows multiple communicative functions of an utterance to be labeled. The Forward Communicative Functions consist of a taxonomy in a similar style as the actions of traditional speech act theory. The Backward Communicative Functions indicate how the current utterance relates to the previous dialog, such as accepting a proposal, con rming understanding, or answering a question. The Utterance Features include information about an utterance's form and content, such as whether an utterance concerns the communication process itself or deals with the subject at hand. The kappa inter-annotator reliability scores for the rst test of DAMSL with human annotators show promise, but are on average 0.15 lower than the accepted kappa scores for such annotations. However, the slight revisions to DAMSL discussed here should increase accuracy on the next set of tests and produce a reliable, exible, and comprehensive utterance annotation scheme.},
  language = {en},
  booktitle = {Working {{Notes}} of the {{AAAI Fall Symposium}} on {{Communicative Action}} in {{Humans}} and {{Machines}}},
  author = {Core, Mark G and Allen, James F},
  year = {1997},
  pages = {28-35},
  file = {/Users/xnobwi/.zotero/storage/BKUWT57X/Core and Allen - Coding Dialogs with the DAMSL Annotation Scheme.pdf}
}

@inproceedings{pragstVectorRepresentationUtterances2018,
  title = {On the {{Vector Representation}} of {{Utterances}} in {{Dialogue Context}}},
  booktitle = {Proceedings of the {{Eleventh International Conference}} on {{Language Resources}} and {{Evaluation}} ({{LREC}}-2018)},
  publisher = {{European Language Resource Association}},
  author = {Pragst, Louisa and Rach, Niklas and Minker, Wolfgang and Ultes, Stefan},
  year = {2018},
  keywords = {suggestion},
  file = {/Users/xnobwi/.zotero/storage/3DEGXJPE/Pragst et al. - 2018 - On the Vector Representation of Utterances in Dial.pdf}
}

@article{devlinBERTPretrainingDeep2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1810.04805},
  primaryClass = {cs},
  title = {{{BERT}}: {{Pre}}-Training of {{Deep Bidirectional Transformers}} for {{Language Understanding}}},
  shorttitle = {{{BERT}}},
  abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT representations can be fine-tuned with just one additional output layer to create state-of-theart models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications.},
  language = {en},
  journal = {arXiv:1810.04805 [cs]},
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  month = oct,
  year = {2018},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/xnobwi/.zotero/storage/CD98FF2E/Devlin et al. - 2018 - BERT Pre-training of Deep Bidirectional Transform.pdf}
}

@article{cerisaraEffectsUsingWord2vec2018,
  title = {On the Effects of Using Word2vec Representations in Neural Networks for Dialogue Act Recognition},
  volume = {47},
  issn = {08852308},
  doi = {10.1016/j.csl.2017.07.009},
  language = {en},
  journal = {Computer Speech \& Language},
  author = {Cerisara, Christophe and Kr\'al, Pavel and Lenc, Ladislav},
  month = jan,
  year = {2018},
  pages = {175-193},
  file = {/Users/xnobwi/.zotero/storage/4WXBE8SF/1-s2.0-S0885230816300456-main.pdf}
}

@book{austinHowThingsWords2009,
  address = {Cambridge, Mass},
  edition = {2. ed., [repr.]},
  title = {How to Do Things with Words: The {{William James}} Lectures Delivered at {{Harvard University}} in 1955},
  isbn = {978-0-674-41152-4},
  shorttitle = {How to Do Things with Words},
  language = {eng},
  publisher = {{Harvard Univ. Press}},
  author = {Austin, John L. and Urmson, James O.},
  year = {2009},
  file = {/Users/xnobwi/.zotero/storage/2MCXA76R/Austin - HOW TO DO THINGS WITH WORDS.pdf},
  note = {OCLC: 935786421}
}

@inproceedings{kalchbrennerRecurrentConvolutionalNeural2013,
  title = {Recurrent {{Convolutional Neural Networks}} for {{Discourse Compositionality}}},
  abstract = {The compositionality of meaning extends beyond the single sentence. Just as words combine to form the meaning of sentences, so do sentences combine to form the meaning of paragraphs, dialogues and general discourse. We introduce both a sentence model and a discourse model corresponding to the two levels of compositionality. The sentence model adopts convolution as the central operation for composing semantic vectors and is based on a novel hierarchical convolutional neural network. The discourse model extends the sentence model and is based on a recurrent neural network that is conditioned in a novel way both on the current sentence and on the current speaker. The discourse model is able to capture both the sequentiality of sentences and the interaction between different speakers. Without feature engineering or pretraining and with simple greedy decoding, the discourse model coupled to the sentence model obtains state of the art performance on a dialogue act classification experiment.},
  language = {en},
  booktitle = {Proceedings of the {{Workshop}} on {{Continuous Vector Space Models}} and Their {{Compositionality}}},
  author = {Kalchbrenner, Nal and Blunsom, Phil},
  year = {2013},
  pages = {119-126},
  file = {/Users/xnobwi/.zotero/storage/SRUYIRW5/Kalchbrenner and Blunsom - Recurrent Convolutional Neural Networks for Discou.pdf}
}

@article{stolckeDialogueActModeling2000,
  title = {Dialogue {{Act Modeling}} for {{Automatic Tagging}} and {{Recognition}} of {{Conversational Speech}}},
  volume = {26},
  issn = {0891-2017, 1530-9312},
  doi = {10.1162/089120100561737},
  language = {en},
  number = {3},
  journal = {Computational Linguistics},
  author = {Stolcke, Andreas and Ries, Klaus and Coccaro, Noah and Shriberg, Elizabeth and Bates, Rebecca and Jurafsky, Daniel and Taylor, Paul and Martin, Rachel and {Ess-Dykema}, Carol Van and Meteer, Marie},
  month = sep,
  year = {2000},
  pages = {339-373},
  file = {/Users/xnobwi/.zotero/storage/E2RM82HV/Stolcke et al. - 2000 - Dialogue Act Modeling for Automatic Tagging and Re.pdf}
}

@inproceedings{sordoniNeuralNetworkApproach2015,
  address = {Denver, Colorado},
  title = {A {{Neural Network Approach}} to {{Context}}-{{Sensitive Generation}} of {{Conversational Responses}}},
  doi = {10.3115/v1/N15-1020},
  abstract = {We present a novel response generation system that can be trained end to end on large quantities of unstructured Twitter conversations. A neural network architecture is used to address sparsity issues that arise when integrating contextual information into classic statistical models, allowing the system to take into account previous dialog utterances. Our dynamic-context generative models show consistent gains over both context-sensitive and non-context-sensitive Machine Translation and Information Retrieval baselines.},
  language = {en},
  booktitle = {Proceedings of the 2015 {{Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Human Language Technologies}}},
  publisher = {{Association for Computational Linguistics}},
  author = {Sordoni, Alessandro and Galley, Michel and Auli, Michael and Brockett, Chris and Ji, Yangfeng and Mitchell, Margaret and Nie, Jian-Yun and Gao, Jianfeng and Dolan, Bill},
  year = {2015},
  pages = {196-205},
  file = {/Users/xnobwi/.zotero/storage/6QR84V9B/Sordoni et al. - 2015 - A Neural Network Approach to Context-Sensitive Gen.pdf}
}


